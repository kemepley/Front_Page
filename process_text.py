import string
import nltk
from nltk.corpus import stopwords
from spacy.lang.en import English
from spacy.tokenizer import Tokenizer
import re

 # stopwords list modified from https://algs4.cs.princeton.edu/35applications/stopwords.txt
stopwords = [
'about',
'above',
'according',
'accordingly',
'across',
'actually',
'after',
'afterwards',
'again',
'ain\'t',
'all',
'allow',
'allows',
'almost',
'along',
'already',
'also',
'although',
'always',
'am',
'among',
'amongst',
'an',
'and',
'another',
'any',
'anybody',
'anyhow',
'anyone',
'anything',
'anyway',
'anyways',
'anywhere',
'apart',
'appear',
'are',
'aren\'t',
'around',
'as',
'aside',
'ask',
'asking',
'associated',
'at',
'available',
'away',
'be',
'became',
'because',
'become',
'becomes',
'becoming',
'been',
'before',
'beforehand',
'behind',
'being',
'below',
'beside',
'besides',
'between',
'beyond',
'both',
'brief',
'by',
'c\'mon',
'came',
'can',
'can\'t',
'cannot',
'cant',
'cause',
'causes',
'certain',
'certainly',
'changes',
'clearly',
'co',
'com',
'come',
'comes',
'consequently',
'consider',
'considering',
'contain',
'containing',
'contains',
'corresponding',
'could',
'couldn\'t',
'course',
'currently',
'definitely',
'described',
'despite',
'did',
'didn\'t',
'different',
'do',
'does',
'doesn\'t',
'doing',
'don\'t',
'done',
'down',
'downwards',
'during',
'each',
'edu',
'eg',
'eight',
'either',
'else',
'elsewhere',
'et',
'etc',
'even',
'ever',
'every',
'everybody',
'everyone',
'everything',
'everywhere',
'ex',
'exactly',
'example',
'except',
'far',
'few',
'fifth',
'first',
'five',
'followed',
'following',
'follows',
'for',
'former',
'formerly',
'forth',
'four',
'from',
'further',
'furthermore',
'get',
'gets',
'getting',
'given',
'gives',
'go',
'goes',
'going',
'gone',
'got',
'gotten',
'greetings',
'had',
'hadn\'t',
'happens',
'hardly',
'has',
'hasn\'t',
'have',
'haven\'t',
'having',
'he',
'he\'s',
'hence',
'her',
'here',
'here\'s',
'hereafter',
'hereby',
'herein',
'hereupon',
'hers',
'herself',
'hi',
'him',
'himself',
'his',
'hither',
'how',
'howbeit',
'however',
'i\'d',
'i\'ll',
'i\'m',
'i\'ve',
'ie',
'if',
'in',
'inasmuch',
'inc',
'indeed',
'indicate',
'indicated',
'indicates',
'inner',
'insofar',
'instead',
'into',
'inward',
'is',
'isn\'t',
'it',
'it\'d',
'it\'ll',
'it\'s',
'its',
'itself',
'just',
'keep',
'keeps',
'kept',
'know',
'knows',
'known',
'last',
'lately',
'later',
'latter',
'latterly',
'least',
'less',
'lest',
'let',
'let\'s',
'likely',
'little',
'look',
'looking',
'looks',
'ltd',
'mainly',
'many',
'may',
'maybe',
'me',
'meanwhile',
'might',
'more',
'moreover',
'most',
'mostly',
'much',
'must',
'my',
'myself',
'name',
'namely',
'nd',
'near',
'nearly',
'necessary',
'neither',
'nevertheless',
'next',
'nine',
'nobody',
'non',
'none',
'noone',
'nor',
'normally',
'nothing',
'now',
'nowhere',
'obviously',
'of',
'off',
'often',
'oh',
'old',
'on',
'once',
'one',
'ones',
'only',
'onto',
'or',
'other',
'others',
'otherwise',
'ought',
'our',
'ours',
'ourselves',
'out',
'outside',
'over',
'overall',
'own',
'particular',
'particularly',
'per',
'perhaps',
'placed',
'possible',
'presumably',
'probably',
'provides',
'que',
'quite',
'qv',
'rather',
'rd',
're',
'reasonably',
'regarding',
'regardless',
'regards',
'relatively',
'respectively',
'said',
'same',
'saw',
'say',
'saying',
'says',
'second',
'secondly',
'see',
'seeing',
'seem',
'seemed',
'seeming',
'seems',
'seen',
'self',
'selves',
'sent',
'seven',
'several',
'shall',
'she',
'should',
'shouldn\'t',
'since',
'six',
'so',
'some',
'somebody',
'somehow',
'someone',
'something',
'sometime',
'sometimes',
'somewhat',
'somewhere',
'soon',
'specified',
'specify',
'specifying',
'sub',
'such',
'sup',
'sure',
'take',
'taken',
'tell',
'tends',
'th',
'than',
'that',
'that\'s',
'thats',
'the',
'their',
'theirs',
'them',
'themselves',
'then',
'thence',
'there',
'there\'s',
'thereafter',
'thereby',
'therefore',
'therein',
'theres',
'thereupon',
'these',
'they',
'they\'d',
'they\'ll',
'they\'re',
'they\'ve',
'think',
'third',
'this',
'thorough',
'thoroughly',
'those',
'though',
'three',
'through',
'throughout',
'thru',
'thus',
'to',
'too',
'took',
'toward',
'towards',
'tried',
'tries',
'try',
'trying',
'twice',
'two',
'un',
'under',
'unless',
'until',
'unto',
'up',
'upon',
'us',
'use',
'used',
'uses',
'using',
'usually',
'various',
'via',
'viz',
'vs',
'was',
'wasn\'t',
'way',
'we',
'we\'d',
'we\'ll',
'we\'re',
'we\'ve',
'went',
'were',
'weren\'t',
'what',
'what\'s',
'whatever',
'when',
'whence',
'whenever',
'where',
'where\'s',
'whereafter',
'whereas',
'whereby',
'wherein',
'whereupon',
'wherever',
'whether',
'which',
'while',
'whither',
'who',
'who\'s',
'whoever',
'whole',
'whom',
'whose',
'why',
'will',
'willing',
'with',
'within',
'without',
'won\'t',
'would',
'would',
'wouldn\'t',
'yes',
'yet',
'you',
'you\'d',
'you\'ll',
'you\'re',
'you\'ve',
'your',
'yours',
'yourself',
'yourselves',
'zero']


def lower(row):

    '''A function that finds all uppercase letters in a row and converts them to lowercase.''' 
    
    return row.lower()

def remove_stopword(row):
    
    '''A function that finds all stopwords in a row and removes them.''' 

    new_row = []
    
    for i in row.split():
        if i not in stopwords:
            new_row.append(i)
    return ' '.join(new_row)

def remove_punctuation(row):

    '''A function that finds punctuation a row and removes it, but keeps ? and ! with added spaces.''' 
    
    row = row.translate(str.maketrans('', '', "~`!@#$%^&*()_-+=/\,.<>\':;"))
    row = re.sub(r'\?', ' ? ', row)
    row = re.sub(r'!', ' ! ', row)

    return row


def lemmatize(row):
        
    '''A function that replaces words with their base forms.''' 
    
    nlp = English()
    tokenize = Tokenizer(nlp.vocab)
    
    new_row = []
    for i in tokenize(row):
        new_row.append(i.lemma_)
    return ' '.join(new_row)

def remove_numbers(row):

    '''A function that finds all numbers a row and removes them.''' 
    
    return row.translate(str.maketrans('', '', string.digits))

class Process_Text_Data:
    
    def __init__(self):
        pass

    def transform(self, data, col='text', RNN=False):   
        
        data[col] = data[col].apply(lower)
        data[col] = data[col].apply(remove_punctuation)
        
        if RNN==False:
            data[col] = data[col].apply(remove_stopword)
            data[col] = data[col].apply(lemmatize)
            data[col] = data[col].apply(remove_numbers)


    